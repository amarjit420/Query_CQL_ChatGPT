{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amarjit420/Query_CQL_ChatGPT/blob/main/Query_CQL_with_ChatGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b69b5b27-f4dc-439b-8ae5-b3f776fa3745",
      "metadata": {
        "id": "b69b5b27-f4dc-439b-8ae5-b3f776fa3745"
      },
      "source": [
        "# Using LLMs to Generate CQL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "107770b0-abda-43ee-af5d-eae2100b65ad",
      "metadata": {
        "id": "107770b0-abda-43ee-af5d-eae2100b65ad"
      },
      "source": [
        "Since LLMs seem to excel at a lot of things, we wanted to show how they can be used to generate CQL to query your Cassandra tables. This notebook provides a guide derived from the [SQL-PaLM](https://arxiv.org/abs/2306.00739) paper on how to automatically show the LLM your DB schema, and let it inform the LLM on querying your data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ffeccb0-d70c-4f15-b924-6e8cd7a5b30e",
      "metadata": {
        "id": "1ffeccb0-d70c-4f15-b924-6e8cd7a5b30e"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b71640c3-3495-4459-837e-08d6e80ed410",
      "metadata": {
        "id": "b71640c3-3495-4459-837e-08d6e80ed410"
      },
      "source": [
        "#### Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b43e0d9c-c760-485f-877b-df577f2cfacf",
      "metadata": {
        "id": "b43e0d9c-c760-485f-877b-df577f2cfacf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4d14ec-13c9-4669-c5fe-a3c3cb4afb61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cassandra-driver\n",
            "  Downloading cassandra_driver-3.29.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.8/18.8 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Collecting geomet<0.3,>=0.1 (from cassandra-driver)\n",
            "  Downloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.1.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, geomet, httpcore, cassandra-driver, httpx, openai\n",
            "Successfully installed cassandra-driver-3.29.0 geomet-0.2.1.post1 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "# Install requirements, if not already installed\n",
        "!pip install openai cassandra-driver"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae7063e7-80c4-49ae-84f1-3345aa3bbef1",
      "metadata": {
        "id": "ae7063e7-80c4-49ae-84f1-3345aa3bbef1"
      },
      "source": [
        "#### Connect to Services"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9767fc7a-a9d8-4e89-b32c-805243700348",
      "metadata": {
        "id": "9767fc7a-a9d8-4e89-b32c-805243700348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb6cd9a-13e8-47e4-d765-0ee9e1b58fbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# Initialize the OpenAI Client\n",
        "import os\n",
        "\n",
        "from getpass import getpass\n",
        "import openai\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API Key: \")\n",
        "\n",
        "client = openai.OpenAI()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6a47bad8-9e13-41fa-af6d-724b72f702cd",
      "metadata": {
        "id": "6a47bad8-9e13-41fa-af6d-724b72f702cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "ce5d97b3-1d5a-4679-eca6-f067d572419a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Astra DB Token: ··········\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b79aca4c-3ffe-4ff9-8eca-87c774f17612\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b79aca4c-3ffe-4ff9-8eca-87c774f17612\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving secure-connect-text-cql-chatgpt.zip to secure-connect-text-cql-chatgpt.zip\n",
            "Astra DB Keyspace: ks1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 18bf2678-ae7a-4109-9348-3b366bce99c0-eu-west-1.db.astra.datastax.com:29042:b8df861c-a1c5-44ee-8ade-0c6e99701d67. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 18bf2678-ae7a-4109-9348-3b366bce99c0-eu-west-1.db.astra.datastax.com:29042:b8df861c-a1c5-44ee-8ade-0c6e99701d67. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(139665211791472) 18bf2678-ae7a-4109-9348-3b366bce99c0-eu-west-1.db.astra.datastax.com:29042:b8df861c-a1c5-44ee-8ade-0c6e99701d67> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 18bf2678-ae7a-4109-9348-3b366bce99c0-eu-west-1.db.astra.datastax.com:29042:b8df861c-a1c5-44ee-8ade-0c6e99701d67. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ],
      "source": [
        "# Connect to a Cassandra Cluster and initialize the session\n",
        "import re\n",
        "\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from getpass import getpass\n",
        "from google.colab import files\n",
        "\n",
        "ASTRA_TOKEN = os.environ.get(\n",
        "    \"ASTRA_DB_TOKEN\",\n",
        "    getpass(\"Astra DB Token: \")\n",
        ")\n",
        "\n",
        "ASTRA_BUNDLE_PATH = os.environ.get(\n",
        "    \"ASTRA_DB_BUNDLE_PATH\",\n",
        "    list(files.upload().keys())[0],\n",
        ")\n",
        "\n",
        "ASTRA_KEYSPACE = os.environ.get(\n",
        "    \"ASTRA_DB_KEYSPACE\",\n",
        "    input(\"Astra DB Keyspace: \"),\n",
        ")\n",
        "\n",
        "cloud_config = {\n",
        "    'secure_connect_bundle': ASTRA_BUNDLE_PATH\n",
        "}\n",
        "auth_provider = PlainTextAuthProvider(\"token\", ASTRA_TOKEN)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect(keyspace=ASTRA_KEYSPACE)\n",
        "\n",
        "\n",
        "def execute_statement(statement: str):\n",
        "    # This is a simple wrapper around executing CQL statements in our\n",
        "    # Cassandra cluster, and either raising an error or returning the results\n",
        "    try:\n",
        "        rows = session.execute(statement)\n",
        "        return rows.all()\n",
        "    except:\n",
        "        print(f\"Query Failed: {statement}\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "890b2537-f585-4f31-bb20-ed71910eb586",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "890b2537-f585-4f31-bb20-ed71910eb586"
      },
      "source": [
        "#### (Optional) Dummy DB Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db89558d-f24b-4517-bf46-97c65c2071ac",
      "metadata": {
        "id": "db89558d-f24b-4517-bf46-97c65c2071ac"
      },
      "source": [
        "Feel free to skip this section if you are instead adapting the notebook to fit your existing Cassandra Database. Here, we will utilize the python `cassandra-driver` package to connect to a DB and create some fake tables. This schema is pulled from [this DataStax example](https://www.datastax.com/learn/data-modeling-by-example/digital-library-data-model) on creating a data model for a digital music library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "df4e69c2-0cda-42e3-8718-8f7ac6da230f",
      "metadata": {
        "id": "df4e69c2-0cda-42e3-8718-8f7ac6da230f"
      },
      "outputs": [],
      "source": [
        "# Create all necessary tables\n",
        "create_tables_cql = \"\"\"CREATE TABLE performers (\n",
        "    name TEXT PRIMARY KEY,\n",
        "    type TEXT,\n",
        "    country TEXT,\n",
        "    born INT,\n",
        "    died INT,\n",
        "    founded INT\n",
        ");\n",
        "\n",
        "CREATE TABLE albums_by_performer (\n",
        "    performer TEXT,\n",
        "    year INT,\n",
        "    title TEXT,\n",
        "    genre TEXT,\n",
        "    PRIMARY KEY (performer, year, title)\n",
        ") WITH CLUSTERING ORDER BY (year DESC, title ASC);\n",
        "\n",
        "CREATE TABLE albums_by_title (\n",
        "    title TEXT,\n",
        "    year INT,\n",
        "    performer TEXT,\n",
        "    genre TEXT,\n",
        "    PRIMARY KEY (title, year)\n",
        ") WITH CLUSTERING ORDER BY (year DESC);\n",
        "\n",
        "CREATE TABLE albums_by_genre (\n",
        "    genre TEXT,\n",
        "    year INT,\n",
        "    performer TEXT,\n",
        "    title TEXT,\n",
        "    PRIMARY KEY (genre, year, performer, title)\n",
        ") WITH CLUSTERING ORDER BY (year DESC,  performer ASC, title ASC);\n",
        "\n",
        "CREATE TABLE tracks_by_title (\n",
        "    title TEXT,\n",
        "    album_title TEXT,\n",
        "    album_year INT,\n",
        "    number INT,\n",
        "    length INT,\n",
        "    genre TEXT,\n",
        "    PRIMARY KEY (title, album_title, album_year, number)\n",
        ") WITH CLUSTERING ORDER BY (album_title ASC, album_year DESC, number ASC);\n",
        "\n",
        "CREATE TABLE tracks_by_album (\n",
        "    album_title TEXT,\n",
        "    album_year INT,\n",
        "    number INT,\n",
        "    title TEXT,\n",
        "    length INT,\n",
        "    genre TEXT STATIC,\n",
        "    PRIMARY KEY (album_title, album_year, number)\n",
        ") WITH CLUSTERING ORDER BY (album_year DESC, number ASC);\n",
        "\n",
        "CREATE TABLE users (\n",
        "    id UUID PRIMARY KEY,\n",
        "    name TEXT\n",
        ");\n",
        "\n",
        "CREATE TABLE tracks_by_user (\n",
        "    id UUID,\n",
        "    month DATE,\n",
        "    timestamp TIMESTAMP,\n",
        "    album_title TEXT,\n",
        "    album_year INT,\n",
        "    number INT,\n",
        "    title TEXT,\n",
        "    length INT,\n",
        "    PRIMARY KEY (id, timestamp)\n",
        ") WITH CLUSTERING ORDER BY (timestamp DESC);\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "03471e5c-47f0-4abd-b742-673a2524f0e2",
      "metadata": {
        "id": "03471e5c-47f0-4abd-b742-673a2524f0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "0420da8a-d3be-4311-d528-12145569dfa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Failed: CREATE TABLE performers (\n",
            "    name TEXT PRIMARY KEY,\n",
            "    type TEXT,\n",
            "    country TEXT,\n",
            "    born INT,\n",
            "    died INT,\n",
            "    founded INT\n",
            ")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AlreadyExists",
          "evalue": "Table 'ks1.performers' already exists",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAlreadyExists\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e5868505ab57>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstatement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcreate_tables_cql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mexecute_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-617bc4191c31>\u001b[0m in \u001b[0;36mexecute_statement\u001b[0;34m(statement)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Cassandra cluster, and either raising an error or returning the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cassandra/cluster.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mcassandra.cluster.Session.execute\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cassandra/cluster.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mcassandra.cluster.ResponseFuture.result\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mAlreadyExists\u001b[0m: Table 'ks1.performers' already exists"
          ]
        }
      ],
      "source": [
        "# This parses the text above into executable strings by the driver\n",
        "for statement in create_tables_cql.split(\";\"):\n",
        "    if len(statement.strip()):\n",
        "        execute_statement(statement.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4698c114-1b77-4613-8555-1122b5a60295",
      "metadata": {
        "id": "4698c114-1b77-4613-8555-1122b5a60295"
      },
      "outputs": [],
      "source": [
        "# Now populate with some fake data\n",
        "insert_fake_data_cql = \"\"\"\n",
        "-- Insert data into performers\n",
        "INSERT INTO performers (name, type, country, born, died, founded) VALUES ('The Beatles', 'Band', 'UK', 1960, NULL, 1960);\n",
        "INSERT INTO performers (name, type, country, born, died, founded) VALUES ('Adele', 'Solo', 'UK', 1988, NULL, NULL);\n",
        "INSERT INTO performers (name, type, country, born, died, founded) VALUES ('Elton John', 'Solo', 'UK', 1947, NULL, NULL);\n",
        "INSERT INTO performers (name, type, country, born, died, founded) VALUES ('Queen', 'Band', 'UK', 1970, NULL, 1970);\n",
        "INSERT INTO performers (name, type, country, born, died, founded) VALUES ('Taylor Swift', 'Solo', 'USA', 1989, NULL, NULL);\n",
        "\n",
        "-- Insert data into albums by performer, title, and genre\n",
        "-- Assuming 'Pop' as a genre for all for simplicity\n",
        "INSERT INTO albums_by_performer (performer, year, title, genre) VALUES ('The Beatles', 1967, 'Sgt. Pepper''s Lonely Hearts Club Band', 'Pop');\n",
        "INSERT INTO albums_by_performer (performer, year, title, genre) VALUES ('Adele', 2015, '25', 'Pop');\n",
        "INSERT INTO albums_by_performer (performer, year, title, genre) VALUES ('Elton John', 1973, 'Goodbye Yellow Brick Road', 'Pop');\n",
        "INSERT INTO albums_by_performer (performer, year, title, genre) VALUES ('Queen', 1975, 'A Night at the Opera', 'Pop');\n",
        "INSERT INTO albums_by_performer (performer, year, title, genre) VALUES ('Taylor Swift', 2014, '1989', 'Pop');\n",
        "\n",
        "-- Repeat for albums_by_title\n",
        "INSERT INTO albums_by_title (title, year, performer, genre) VALUES ('Sgt. Pepper''s Lonely Hearts Club Band', 1967, 'The Beatles', 'Pop');\n",
        "INSERT INTO albums_by_title (title, year, performer, genre) VALUES ('25', 2015, 'Adele', 'Pop');\n",
        "INSERT INTO albums_by_title (title, year, performer, genre) VALUES ('Goodbye Yellow Brick Road', 1973, 'Elton John', 'Pop');\n",
        "INSERT INTO albums_by_title (title, year, performer, genre) VALUES ('A Night at the Opera', 1975, 'Queen', 'Pop');\n",
        "INSERT INTO albums_by_title (title, year, performer, genre) VALUES ('1989', 2014, 'Taylor Swift', 'Pop');\n",
        "\n",
        "-- Repeat for albums_by_genre\n",
        "INSERT INTO albums_by_genre (genre, year, performer, title) VALUES ('Pop', 1967, 'The Beatles', 'Sgt. Pepper''s Lonely Hearts Club Band');\n",
        "INSERT INTO albums_by_genre (genre, year, performer, title) VALUES ('Pop', 2015, 'Adele', '25');\n",
        "INSERT INTO albums_by_genre (genre, year, performer, title) VALUES ('Pop', 1973, 'Elton John', 'Goodbye Yellow Brick Road');\n",
        "INSERT INTO albums_by_genre (genre, year, performer, title) VALUES ('Pop', 1975, 'Queen', 'A Night at the Opera');\n",
        "INSERT INTO albums_by_genre (genre, year, performer, title) VALUES ('Pop', 2014, 'Taylor Swift', '1989');\n",
        "\n",
        "-- Insert data into tracks_by_title and tracks_by_album\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Lucy in the Sky with Diamonds', 'Sgt. Pepper''s Lonely Hearts Club Band', 1967, 1, 208, 'Pop');\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('With a Little Help from My Friends', 'Sgt. Pepper''s Lonely Hearts Club Band', 1967, 2, 163, 'Pop');\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Sgt. Pepper''s Lonely Hearts Club Band', 'Sgt. Pepper''s Lonely Hearts Club Band', 1967, 3, 122, 'Pop');\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Getting Better', 'Sgt. Pepper''s Lonely Hearts Club Band', 1967, 4, 174, 'Pop');\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Fixing a Hole', 'Sgt. Pepper''s Lonely Hearts Club Band', 1967, 5, 139, 'Pop');\n",
        "\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Hello', '25', 2015, 1, 295, 'Pop');\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Send My Love', '25', 2015, 2, 223, 'Pop');\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('I Miss You', '25', 2015, 3, 350, 'Pop');\n",
        "\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Candle in the Wind', 'Goodbye Yellow Brick Road', 1973, 1, 219, 'Pop');\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Bennie and the Jets', 'Goodbye Yellow Brick Road', 1973, 2, 323, 'Pop');\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Goodbye Yellow Brick Road', 'Goodbye Yellow Brick Road', 1973, 3, 193, 'Pop');\n",
        "\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Bohemian Rhapsody', 'A Night at the Opera', 1975, 1, 354, 'Pop');\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Love of My Life', 'A Night at the Opera', 1975, 2, 220, 'Pop');\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Youre My Best Friend', 'A Night at the Opera', 1975, 3, 178, 'Pop');\n",
        "\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Welcome to New York', '1989', 2014, 1, 212, 'Pop');\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Blank Space', '1989', 2014, 2, 231, 'Pop');\n",
        "INSERT INTO tracks_by_title (title, album_title, album_year, number, length, genre) VALUES ('Style', '1989', 2014, 3, 230, 'Pop');\n",
        "\n",
        "-- Repeat for tracks_by_album with corresponding track numbers\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('Sgt. Pepper''s Lonely Hearts Club Band', 1967, 1, 'Lucy in the Sky with Diamonds', 208, 'Pop');\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('Sgt. Pepper''s Lonely Hearts Club Band', 1967, 2, 'With a Little Help from My Friends', 163, 'Pop');\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('Sgt. Pepper''s Lonely Hearts Club Band', 1967, 3, 'Sgt. Pepper''s Lonely Hearts Club Band', 122, 'Pop');\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('Sgt. Pepper''s Lonely Hearts Club Band', 1967, 4, 'Getting Better', 174, 'Pop');\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('Sgt. Pepper''s Lonely Hearts Club Band', 1967, 5, 'Fixing a Hole', 139, 'Pop');\n",
        "\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('25', 2015, 1, 'Hello', 295, 'Pop');\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('25', 2015, 2, 'Send My Love', 223, 'Pop');\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('25', 2015, 3, 'I Miss You', 350, 'Pop');\n",
        "\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('Goodbye Yellow Brick Road', 1973, 1, 'Candle in the Wind', 219, 'Pop');\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('Goodbye Yellow Brick Road', 1973, 2, 'Bennie and the Jets', 323, 'Pop');\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('Goodbye Yellow Brick Road', 1973, 3, 'Goodbye Yellow Brick Road', 193, 'Pop');\n",
        "\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('A Night at the Opera', 1975, 1, 'Bohemian Rhapsody', 354, 'Pop');\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('A Night at the Opera', 1975, 2, 'Love of My Life', 220, 'Pop');\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('A Night at the Opera', 1975, 3, 'Youre My Best Friend', 178, 'Pop');\n",
        "\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('1989', 2014, 1, 'Welcome to New York', 212, 'Pop');\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('1989', 2014, 2, 'Blank Space', 231, 'Pop');\n",
        "INSERT INTO tracks_by_album (album_title, album_year, number, title, length, genre) VALUES ('1989', 2014, 3, 'Style', 230, 'Pop');\n",
        "\n",
        "-- Insert data into users\n",
        "INSERT INTO users (id, name) VALUES (uuid(), 'John Doe');\n",
        "INSERT INTO users (id, name) VALUES (uuid(), 'Jane Smith');\n",
        "INSERT INTO users (id, name) VALUES (uuid(), 'Emily Johnson');\n",
        "INSERT INTO users (id, name) VALUES (uuid(), 'Michael Brown');\n",
        "INSERT INTO users (id, name) VALUES (uuid(), 'Jessica Davis');\n",
        "\n",
        "-- Insert data into tracks_by_user\n",
        "-- User ids should be copied from the users insert statements once generated\n",
        "-- The following are placeholders and should be replaced with actual UUIDs\n",
        "INSERT INTO tracks_by_user (id, month, timestamp, album_title, album_year, number, title, length) VALUES (uuid(), '2024-01-01', toTimestamp(now()), 'Sgt. Pepper''s Lonely Hearts Club Band', 1967, 1, 'Lucy in the Sky with Diamonds', 208);\n",
        "INSERT INTO tracks_by_user (id, month, timestamp, album_title, album_year, number, title, length) VALUES (uuid(), '2024-01-01', toTimestamp(now()), 'Sgt. Pepper''s Lonely Hearts Club Band', 1967, 2, 'With a Little Help from My Friends', 163);\n",
        "INSERT INTO tracks_by_user (id, month, timestamp, album_title, album_year, number, title, length) VALUES (uuid(), '2024-01-01', toTimestamp(now()), 'Sgt. Pepper''s Lonely Hearts Club Band', 1967, 3, 'Sgt. Pepper''s Lonely Hearts Club Band', 122);\n",
        "INSERT INTO tracks_by_user (id, month, timestamp, album_title, album_year, number, title, length) VALUES (uuid(), '2024-01-01', toTimestamp(now()), 'Sgt. Pepper''s Lonely Hearts Club Band', 1967, 4, 'Getting Better', 174);\n",
        "INSERT INTO tracks_by_user (id, month, timestamp, album_title, album_year, number, title, length) VALUES (uuid(), '2024-01-01', toTimestamp(now()), 'Sgt. Pepper''s Lonely Hearts Club Band', 1967, 5, 'Fixing a Hole', 139);\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "71fe8d93-322d-407f-a1ed-406366a9ddbf",
      "metadata": {
        "id": "71fe8d93-322d-407f-a1ed-406366a9ddbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "c98131e0-02f3-47cf-d65f-b726b7e62eee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query Failed: INSERT INTO albums_by_genre (genre, year, performer, title) VALUES ('Pop', 1967, 'The Beatles', 'Sgt. Pepper''s Lonely Hearts Club Band')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidRequest",
          "evalue": "Error from server: code=2200 [Invalid query] message=\"table ks1.albums_by_genre does not exist\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequest\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3231c57c8497>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msc_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msc_loc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mexecute_statement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msc_loc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-617bc4191c31>\u001b[0m in \u001b[0;36mexecute_statement\u001b[0;34m(statement)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Cassandra cluster, and either raising an error or returning the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cassandra/cluster.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mcassandra.cluster.Session.execute\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cassandra/cluster.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mcassandra.cluster.ResponseFuture.result\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mInvalidRequest\u001b[0m: Error from server: code=2200 [Invalid query] message=\"table ks1.albums_by_genre does not exist\""
          ]
        }
      ],
      "source": [
        "# This parses the text above into executable strings by the driver\n",
        "for line in insert_fake_data_cql.split(\"\\n\"):\n",
        "    sc_loc = line.find(\";\")\n",
        "    if sc_loc > -1:\n",
        "        execute_statement(line[:sc_loc])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2495b975-8342-4386-b92d-5ae05b783853",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "2495b975-8342-4386-b92d-5ae05b783853"
      },
      "source": [
        "## (Optional) Give the LLM Additional Context with the Built-in 'Comments' Column"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23820cb9-d683-48bb-9440-b398446df4c9",
      "metadata": {
        "id": "23820cb9-d683-48bb-9440-b398446df4c9"
      },
      "source": [
        "LLM response quality greatly depends on the context they've been given - the more concise descriptions they have access to, the better. We can choose to augment the DB schema we pass to the model by utilizing the built-in `comment` property of CQL tables.\n",
        "\n",
        "NOTE: You can also include these comments at table creation by using the `WITH <table property 1> AND <table property 2> ... AND comment = '<comment>'` syntax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "04d67d6c-6938-46ac-a5b5-8baaea54272a",
      "metadata": {
        "id": "04d67d6c-6938-46ac-a5b5-8baaea54272a"
      },
      "outputs": [],
      "source": [
        "add_comments_cql = f\"\"\"\n",
        "ALTER TABLE albums_by_genre WITH comment = 'Albums partitioned by musical genre';\n",
        "ALTER TABLE albums_by_performer WITH comment = 'Albums partitioned by name of performer/artist';\n",
        "ALTER TABLE albums_by_title WITH comment = 'Albums partitioned by album title';\n",
        "ALTER TABLE performers WITH comment = 'Performers/artists partitioned by performer name';\n",
        "ALTER TABLE tracks_by_album WITH comment = 'Tracks/songs partitioned by album title';\n",
        "ALTER TABLE tracks_by_title WITH comment = 'Tracks/songs partitioned by song title';\n",
        "ALTER TABLE tracks_by_user WITH comment = 'Tracks/songs users listened to partitioned by user ID and time of listen';\n",
        "ALTER TABLE users WITH comment = 'Users partitioned by user ID';\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "db29bea2-7600-495b-b57b-e2937fb0753f",
      "metadata": {
        "id": "db29bea2-7600-495b-b57b-e2937fb0753f"
      },
      "outputs": [],
      "source": [
        "# This parses the text above into executable strings by the driver\n",
        "for line in add_comments_cql.split(\"\\n\"):\n",
        "    sc_loc = line.find(\";\")\n",
        "    if sc_loc > -1:\n",
        "        execute_statement(line[:sc_loc])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a07cc49-7ba3-45ee-b2da-7fd297d8a86d",
      "metadata": {
        "id": "1a07cc49-7ba3-45ee-b2da-7fd297d8a86d"
      },
      "source": [
        "## Run Queries from User Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "942613bc-25aa-41cc-80e9-78ca15bcee06",
      "metadata": {
        "id": "942613bc-25aa-41cc-80e9-78ca15bcee06"
      },
      "source": [
        "#### Generating & Executing CQL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8542b137-2fd1-4105-a402-17358647f815",
      "metadata": {
        "id": "8542b137-2fd1-4105-a402-17358647f815"
      },
      "source": [
        "Now, we can ask ChatGPT to provide us with some queries that answer our questions! The prompt template we use is taken from [SQL-PaLM](https://arxiv.org/abs/2306.00739), and adapted to fit the CQL use case. In order to use it though, we need to retrieve the schema from our DB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7f442866-55e8-4284-83e1-705bb320250b",
      "metadata": {
        "id": "7f442866-55e8-4284-83e1-705bb320250b"
      },
      "outputs": [],
      "source": [
        "TEXT2CQL_PROMPT = \"\"\"Convert the question to CQL (Cassandra Query Language) that can retrieve an appropriate answer, or answer saying that the data model does not support answering such a question in a performant way:\n",
        "\n",
        "[Schema : values (type)]\n",
        "{schema}\n",
        "\n",
        "[Partition Keys]\n",
        "{partition_keys}\n",
        "\n",
        "[Clustering Keys]\n",
        "{clustering_keys}\n",
        "\n",
        "[Q]\n",
        "{question}\n",
        "\n",
        "[CQL]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generate_schema_partition_clustering_keys(keyspace: str = ASTRA_KEYSPACE) -> (str, str):\n",
        "    \"\"\"Generates a TEXT2CQL_PROMPT compatible schema for a keyspace\"\"\"\n",
        "    # Get all table names in our keyspace\n",
        "    table_names = execute_statement(\n",
        "        f\"SELECT table_name, comment FROM system_schema.tables WHERE keyspace_name = '{keyspace}'\"\n",
        "    )\n",
        "    tn_str = \", \".join([\"'\" + tn.table_name + \"'\" for tn in table_names])\n",
        "\n",
        "    # Now get all the column names corresponding to those tables\n",
        "    columns = execute_statement(\n",
        "        f\"SELECT * FROM system_schema.columns WHERE table_name IN ({tn_str}) AND keyspace_name = '{keyspace}' ALLOW FILTERING\"\n",
        "    )\n",
        "\n",
        "    # Now, we construct our prompt template formatted schema, partition_keys, and clustering keys\n",
        "    # from the table and column objects returned from the DB\n",
        "    schema = \" | \".join([\n",
        "        f\"{table.table_name} '{table.comment}' : \" + \" , \".join([\n",
        "            f\"{col.column_name} ({col.type})\"\n",
        "            for col in columns\n",
        "            if col.table_name == table.table_name\n",
        "        ])\n",
        "        for table in table_names\n",
        "    ])\n",
        "    partition_keys = \" | \".join([\n",
        "        f\"{table.table_name} : \" + \" , \".join([\n",
        "            col.column_name for col in columns\n",
        "            if col.table_name == table.table_name\n",
        "            and col.kind == \"partition_key\"\n",
        "        ])\n",
        "        for table in table_names\n",
        "    ])\n",
        "    clustering_keys = \" | \".join([\n",
        "        f\"{table.table_name} : \" + \" , \".join([\n",
        "            f\"{col.column_name} ({col.clustering_order})\" for col in columns\n",
        "            if col.table_name == table.table_name\n",
        "            and col.kind == \"clustering\"\n",
        "        ])\n",
        "        for table in table_names\n",
        "    ])\n",
        "    return schema, partition_keys, clustering_keys\n",
        "\n",
        "\n",
        "def execute_query_from_question(question: str, debug_cql: bool = True, debug_prompt: bool = False, return_cql: bool = False):\n",
        "    \"\"\"Generates and executes CQL from a user question based on LLM output\"\"\"\n",
        "    # Get all of the variables necessary to fill out the prompt\n",
        "    schema, partition_keys, clustering_keys = generate_schema_partition_clustering_keys()\n",
        "    prompt = TEXT2CQL_PROMPT.format(\n",
        "        schema=schema,\n",
        "        partition_keys=partition_keys,\n",
        "        clustering_keys=clustering_keys,\n",
        "        question=question,\n",
        "    )\n",
        "\n",
        "    if debug_prompt:\n",
        "        print(f\"Prompting model with:\\n{prompt}\")\n",
        "\n",
        "    # Get generated CQL from the LLM (in this case gpt-3.5-turbo)\n",
        "    completion = client.chat.completions.create(\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }],\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    if debug_cql:\n",
        "        print(f\"Question: {question}\\nGenerated Query: {completion}\\n\")\n",
        "\n",
        "    # Need to trim trailing ';' if present to work with cassandra-driver\n",
        "    if completion.find(\";\") > -1:\n",
        "        completion = completion[:completion.find(\";\")]\n",
        "\n",
        "    results = execute_statement(completion)\n",
        "\n",
        "    if return_cql:\n",
        "        return (results, completion)\n",
        "    else:\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dd55a635-d1f5-4463-afff-b98b7bf23b56",
      "metadata": {
        "id": "dd55a635-d1f5-4463-afff-b98b7bf23b56",
        "outputId": "bfeaea80-d85c-40c0-f2a8-584454bc896a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompting model with:\n",
            "Convert the question to CQL (Cassandra Query Language) that can retrieve an appropriate answer, or answer saying that the data model does not support answering such a question in a performant way:\n",
            "\n",
            "[Schema : values (type)]\n",
            "albums_by_genre 'Albums partitioned by musical genre' : genre (text) , performer (text) , title (text) , year (int) | albums_by_performer 'Albums partitioned by name of performer/artist' : genre (text) , performer (text) , title (text) , year (int) | albums_by_title 'Albums partitioned by album title' : genre (text) , performer (text) , title (text) , year (int) | performers 'Performers/artists partitioned by performer name' : born (int) , country (text) , died (int) , founded (int) , name (text) , type (text) | tracks_by_album 'Tracks/songs partitioned by album title' : album_title (text) , album_year (int) , genre (text) , length (int) , number (int) , title (text) | tracks_by_title 'Tracks/songs partitioned by song title' : album_title (text) , album_year (int) , genre (text) , length (int) , number (int) , title (text) | tracks_by_user 'Tracks/songs users listened to partitioned by user ID and time of listen' : album_title (text) , album_year (int) , id (uuid) , length (int) , month (date) , number (int) , timestamp (timestamp) , title (text) | users 'Users partitioned by user ID' : id (uuid) , name (text)\n",
            "\n",
            "[Partition Keys]\n",
            "albums_by_genre : genre | albums_by_performer : performer | albums_by_title : title | performers : name | tracks_by_album : album_title | tracks_by_title : title | tracks_by_user : id | users : id\n",
            "\n",
            "[Clustering Keys]\n",
            "albums_by_genre : performer (asc) , title (asc) , year (desc) | albums_by_performer : title (asc) , year (desc) | albums_by_title : year (desc) | performers :  | tracks_by_album : album_year (desc) , number (asc) | tracks_by_title : album_title (asc) , album_year (desc) , number (asc) | tracks_by_user : timestamp (desc) | users : \n",
            "\n",
            "[Q]\n",
            "What songs are on A Night at the Opera?\n",
            "\n",
            "[CQL]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-3b557146f774>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Show full prompting trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexecute_query_from_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What songs are on A Night at the Opera?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-f720615b8c52>\u001b[0m in \u001b[0;36mexecute_query_from_question\u001b[0;34m(question, debug_cql, debug_prompt, return_cql)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# Get generated CQL from the LLM (in this case gpt-3.5-turbo)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m     77\u001b[0m         messages=[{\n\u001b[1;32m     78\u001b[0m             \u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 663\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    664\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1198\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         )\n\u001b[0;32m-> 1200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 889\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    966\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    966\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ],
      "source": [
        "# Show full prompting trace\n",
        "execute_query_from_question(\"What songs are on A Night at the Opera?\", debug_prompt=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ae4ade-dc9c-4cae-824f-98edc5bc5208",
      "metadata": {
        "id": "b3ae4ade-dc9c-4cae-824f-98edc5bc5208",
        "outputId": "bb3c1b4b-dd61-48c9-99bf-8d2db543bbe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are some of the most recent Pop albums in the last decade?\n",
            "Generated Query: SELECT title, year FROM albums_by_genre WHERE genre = 'Pop' AND year >= 2010 ALLOW FILTERING;\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(title='25', year=2015), Row(title='1989', year=2014)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "execute_query_from_question(\"What are some of the most recent Pop albums in the last decade?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51e97f95-5f44-4de5-9342-1c00b30918c4",
      "metadata": {
        "id": "51e97f95-5f44-4de5-9342-1c00b30918c4",
        "outputId": "4231b990-e0f7-4824-e3f4-46450bbcc3ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How many albums has Taylor Swift made?\n",
            "Generated Query: SELECT COUNT(*) FROM albums_by_performer WHERE performer = 'Taylor Swift';\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(count=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "execute_query_from_question(\"How many albums has Taylor Swift made?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7adb085f-48af-422b-9e9e-15c2d02a4f58",
      "metadata": {
        "id": "7adb085f-48af-422b-9e9e-15c2d02a4f58"
      },
      "source": [
        "Pretty cool that it can find the data to answer our questions! Let's see if we can take this one step further, and actually generate coherent responses using this data:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8afb916-f30b-4bed-9e00-5e86b261d788",
      "metadata": {
        "id": "d8afb916-f30b-4bed-9e00-5e86b261d788"
      },
      "source": [
        "#### End to End Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09aa4a19-a284-4800-abb0-8d0e24185c38",
      "metadata": {
        "id": "09aa4a19-a284-4800-abb0-8d0e24185c38"
      },
      "source": [
        "Now, let's wrap up by showing how we can make a subsequent LLM call to answer the user's question with natural language. This completes a full \"RAG\" style pipeline!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb6002e-d5f1-408c-9bd3-e7ca4a329483",
      "metadata": {
        "id": "dbb6002e-d5f1-408c-9bd3-e7ca4a329483"
      },
      "outputs": [],
      "source": [
        "ANSWER_PROMPT = \"\"\"Query:\n",
        "```\n",
        "{cql}\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "{results_repr}\n",
        "```\n",
        "===\n",
        "\n",
        "Given the above results from querying the DB, answer the following user question:\n",
        "\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def answer_question(question: str, debug_cql: bool = False, debug_prompt: bool = False) -> str:\n",
        "    \"\"\"Conducts a full RAG pipeline where the LLM retrieves relevant information\n",
        "    and references it to answer the question in natural language.\n",
        "    \"\"\"\n",
        "    # Get necessary fields to fill out prompt\n",
        "    query_results, cql = execute_query_from_question(\n",
        "        question=question,\n",
        "        debug_cql=debug_cql,\n",
        "        debug_prompt=debug_prompt,\n",
        "        return_cql=True,\n",
        "    )\n",
        "    prompt = ANSWER_PROMPT.format(\n",
        "        question=question,\n",
        "        results_repr=str(query_results),\n",
        "        cql=cql,\n",
        "    )\n",
        "\n",
        "    if debug_prompt:\n",
        "        print(f\"Prompting model with:\\n{prompt}\")\n",
        "\n",
        "    # Return the generated answer from the LLM\n",
        "    return client.chat.completions.create(\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }],\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "    ).choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8533ecb1-9c8e-4db1-beb4-e736d2a1b500",
      "metadata": {
        "id": "8533ecb1-9c8e-4db1-beb4-e736d2a1b500",
        "outputId": "68d0beca-86cc-47b2-b96e-b6c6d1c5f1e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompting model with:\n",
            "Convert the question to CQL (Cassandra Query Language) that can retrieve an appropriate answer, or answer saying that the data model does not support answering such a question in a performant way:\n",
            "\n",
            "[Schema : values (type)]\n",
            "albums_by_genre 'Albums partitioned by musical genre' : genre (text) , performer (text) , title (text) , year (int) | albums_by_performer 'Albums partitioned by name of performer/artist' : genre (text) , performer (text) , title (text) , year (int) | albums_by_title 'Albums partitioned by album title' : genre (text) , performer (text) , title (text) , year (int) | performers 'Performers/artists partitioned by performer name' : born (int) , country (text) , died (int) , founded (int) , name (text) , type (text) | tracks_by_album 'Tracks/songs partitioned by album title' : album_title (text) , album_year (int) , genre (text) , length (int) , number (int) , title (text) | tracks_by_title 'Tracks/songs partitioned by song title' : album_title (text) , album_year (int) , genre (text) , length (int) , number (int) , title (text) | tracks_by_user 'Tracks/songs users listened to partitioned by user ID and time of listen' : album_title (text) , album_year (int) , id (uuid) , length (int) , month (date) , number (int) , timestamp (timestamp) , title (text) | users 'Users partitioned by user ID' : id (uuid) , name (text)\n",
            "\n",
            "[Partition Keys]\n",
            "albums_by_genre : genre | albums_by_performer : performer | albums_by_title : title | performers : name | tracks_by_album : album_title | tracks_by_title : title | tracks_by_user : id | users : id\n",
            "\n",
            "[Clustering Keys]\n",
            "albums_by_genre : performer (asc) , title (asc) , year (desc) | albums_by_performer : title (asc) , year (desc) | albums_by_title : year (desc) | performers :  | tracks_by_album : album_year (desc) , number (asc) | tracks_by_title : album_title (asc) , album_year (desc) , number (asc) | tracks_by_user : timestamp (desc) | users : \n",
            "\n",
            "[Q]\n",
            "What songs are on A Night at the Opera?\n",
            "\n",
            "[CQL]\n",
            "\n",
            "Prompting model with:\n",
            "Query:\n",
            "```\n",
            "SELECT title \n",
            "FROM tracks_by_album \n",
            "WHERE album_title = 'A Night at the Opera'\n",
            "```\n",
            "\n",
            "Output:\n",
            "```\n",
            "[Row(title='Bohemian Rhapsody'), Row(title='Love of My Life'), Row(title='Youre My Best Friend')]\n",
            "```\n",
            "===\n",
            "\n",
            "Given the above results from querying the DB, answer the following user question:\n",
            "\n",
            "What songs are on A Night at the Opera?\n",
            "\n",
            "The songs on \"A Night at the Opera\" are \"Bohemian Rhapsody\", \"Love of My Life\", and \"You're My Best Friend\".\n"
          ]
        }
      ],
      "source": [
        "# Show full prompting trace\n",
        "print(\n",
        "    answer_question(\"What songs are on A Night at the Opera?\", debug_prompt=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32edcf7a-ea91-4ae9-9543-3b987a3cb695",
      "metadata": {
        "id": "32edcf7a-ea91-4ae9-9543-3b987a3cb695",
        "outputId": "713721a2-da55-45b5-8a4a-b285c588d6a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some of the most recent Pop albums in the last decade are \"25\" by Adele (released in 2015) and \"1989\" by Taylor Swift (released in 2014).\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    answer_question(\"What are some of the most recent Pop albums in the last decade?\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3083b6cb-7e4c-4738-b934-a4e49ac372cb",
      "metadata": {
        "id": "3083b6cb-7e4c-4738-b934-a4e49ac372cb",
        "outputId": "ae8b1eef-1871-4772-fec7-8ee279df7a8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taylor Swift has made 1 album.\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    answer_question(\"How many albums has Taylor Swift made?\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29edd522-6cb9-454c-a5b3-b8ee0f8a9ea8",
      "metadata": {
        "id": "29edd522-6cb9-454c-a5b3-b8ee0f8a9ea8"
      },
      "source": [
        "Awesome! Our model is answering questions based on just the data in our dummy DB, and is able to construct queries for retrieving that data in a fully automated way."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "890b2537-f585-4f31-bb20-ed71910eb586",
        "2495b975-8342-4386-b92d-5ae05b783853"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}